# Architecture Globale OpenShift AI 2.22

## üèóÔ∏è Vue d'ensemble

OpenShift AI 2.22 est construit sur une architecture modulaire utilisant un meta-operator qui d√©ploie et g√®re tous les composants via un objet DataScienceCluster sur OpenShift Container Platform 4.19.

## üìä Diagramme interactif

üëâ **[Voir le diagramme interactif complet](./index.html)**

## üéõÔ∏è Meta-Operator : Red Hat OpenShift AI Operator

**D√©finition officielle** : *Un m√©ta-op√©rateur qui d√©ploie et maintient tous les composants et sous-op√©rateurs qui font partie d'OpenShift AI.*

### DataScienceCluster (DSC)
L'objet principal qui configure tous les composants OpenShift AI :

```yaml
apiVersion: datasciencecluster.opendatahub.io/v1
kind: DataScienceCluster
metadata:
  name: default-dsc
spec:
  components:
    dashboard:
      managementState: Managed
    workbenches:
      managementState: Managed
    kserve:
      managementState: Managed
    modelmeshserving:
      managementState: Managed
    datasciencepipelines:
      managementState: Managed
    # ... autres composants
```

### Configuration managementState
- **Managed** : L'op√©rateur g√®re activement le composant, l'installe, et essaie de le maintenir actif
- **Removed** : L'op√©rateur g√®re activement le composant mais ne l'installe pas. Si d√©j√† install√©, l'op√©rateur essaiera de le supprimer

## üìÅ Namespaces cr√©√©s automatiquement

Lors de l'installation de l'op√©rateur, les namespaces suivants sont cr√©√©s :

- **`redhat-ods-operator`** : Contient l'op√©rateur Red Hat OpenShift AI
- **`redhat-ods-applications`** : Installe le dashboard et autres composants requis
- **`redhat-ods-monitoring`** : Contient les services de monitoring et facturation
- **`rhods-notebooks`** : O√π les environnements de notebooks sont d√©ploy√©s par d√©faut

## üß© Composants Core

### Dashboard
*Un dashboard orient√© client qui montre les applications disponibles et install√©es pour l'environnement OpenShift AI ainsi que les ressources d'apprentissage comme les tutoriels, guides de d√©marrage rapide et documentation.*

**Fonctionnalit√©s** :
- Interface web utilisateur
- Gestion des projets et utilisateurs
- Configuration des images de notebooks
- Gestion des profils d'acc√©l√©rateurs GPU
- Administration des runtimes de serving

### Workbenches
*Une application auto-g√©r√©e qui permet aux data scientists de configurer leur propre environnement de serveur de notebooks et d√©velopper des mod√®les de machine learning dans JupyterLab.*

**Caract√©ristiques** :
- Environnements JupyterLab personnalisables
- Images de base configurables
- Int√©gration avec stockage persistant
- Support GPU optionnel

### Model Registry (üÜï Nouveaut√© 2.22)
*Les op√©rateurs Red Hat Authorino, Red Hat OpenShift Serverless, et Red Hat OpenShift Service Mesh ne sont plus requis pour utiliser le composant model registry dans OpenShift AI.*

**Am√©liorations 2.22** :
- OAuth Proxy int√©gr√© remplace Authorino
- Migration automatique des instances existantes
- Simplification de l'installation
- Nouvelles instances utilisent OAuth proxy par d√©faut

## üöÄ Model Serving Components

### KServe (Single-Model Serving)
*Pour les mod√®les volumineux, comme les grands mod√®les de langage, la plateforme Single-Model Serving utilise KServe, d√©ployant chaque mod√®le sur son propre serveur.*

**Modes de d√©ploiement** :
- **Serverless** : Utilise Knative pour autoscaling
- **RawDeployment** : D√©ploiement standard Kubernetes

**D√©pendances** :
- Red Hat OpenShift Serverless (pour mode Serverless)
- Red Hat OpenShift Service Mesh (pour mode Advanced)
- Authorino (optionnel, pour authentification)

### ModelMesh (Multi-Model Serving)
*Pour les mod√®les petits et moyens, la plateforme Multi-Model Serving utilise ModelMesh pour d√©ployer plusieurs mod√®les sur un serveur unique, partageant les ressources efficacement.*

**Avantages** :
- Optimisation des ressources
- Partage efficace des co√ªts
- Gestion centralis√©e
- Surveillance unifi√©e

## ‚öôÔ∏è MLOps & Pipeline Components

### Data Science Pipelines
*Les data scientists peuvent construire des workflows de machine learning (ML) portables avec data science pipelines 2.0, utilisant des conteneurs Docker.*

**Mise √† jour 2.22** : Kubeflow Pipelines version 2.5.0

**Fonctionnalit√©s** :
- Workflows automatis√©s
- Conteneurs Docker
- Orchestration des √©tapes ML
- Int√©gration avec stockage S3

### TrustyAI
**Fonctionnalit√©s** :
- Monitoring des mod√®les en production
- Explicabilit√© de l'IA
- D√©tection de biais
- M√©triques de performance

## üñ•Ô∏è Distributed Workloads

*Les data scientists peuvent utiliser plusieurs n≈ìuds en parall√®le pour entra√Æner des mod√®les de machine learning ou traiter des donn√©es plus rapidement.*

### CodeFlare
- SDK Python pour orchestration distribu√©e
- Interface simplifi√©e pour Ray
- Gestion des ressources automatis√©e

### Ray
- Calcul distribu√© et parallel processing
- Mise √† l'√©chelle automatique
- Support pour machine learning distribu√©

### Kueue
- Gestion des queues de travail
- Planification intelligente des ressources
- Partage √©quitable des ressources

### Training Operator
- Entra√Ænement ML distribu√©
- Support pour jobs parall√®les
- Optimisation multi-GPU

## üîó D√©pendances Externes

### Op√©rateurs requis pour KServe
- **Red Hat OpenShift Serverless** : Knative Serving/Eventing
- **Red Hat OpenShift Service Mesh** : Istio Control Plane
- **Red Hat - Authorino** (optionnel) : Authentification des mod√®les

### Stockage
**Requis** : Stockage compatible S3 (AWS S3, MinIO, Ceph, IBM Cloud Storage)
**Utilisation** :
- Stockage des mod√®les ML
- Artifacts des pipelines
- Donn√©es d'entra√Ænement
- Logs et m√©triques

### Support GPU (optionnel)
- **NVIDIA GPU Operator**
- **Node Feature Discovery Operator**

## üÜï Nouveaut√©s principales OpenShift AI 2.22

### Simplification du Model Registry
- **Avant** : N√©cessitait Authorino + Serverless + Service Mesh
- **Maintenant** : OAuth Proxy int√©gr√© uniquement
- **Migration** : Automatique pour les instances existantes

### Am√©lioration de la r√©silience
- **Op√©rateur** : Maintenant avec 3 r√©pliques
- **Haute disponibilit√©** : Am√©lioration de la r√©silience pour les workloads de production
- **Distribution des webhooks** : Op√©rations r√©parties sur plusieurs instances

### Mise √† niveau des pipelines
- **Kubeflow Pipelines 2.5.0** : Nouvelles fonctionnalit√©s et corrections
- **Compatibilit√© am√©lior√©e** : Meilleure int√©gration avec l'√©cosyst√®me

## üìö Documentation officielle

### Sources principales
- [Architecture d'OpenShift AI Cloud Service](https://docs.redhat.com/en/documentation/red_hat_openshift_ai_cloud_service/1/html/installing_and_uninstalling_openshift_ai_cloud_service/architecture-of-openshift-ai_install)
- [Architecture OpenShift AI Self-Managed](https://docs.redhat.com/en/documentation/red_hat_openshift_ai_self-managed/2-latest/html/installing_and_uninstalling_openshift_ai_self-managed/architecture-of-openshift-ai-self-managed_install)
- [Installation et d√©ploiement](https://docs.redhat.com/en/documentation/red_hat_openshift_ai_cloud_service/1/html/installing_and_uninstalling_openshift_ai_cloud_service/installing-and-deploying-openshift-ai_install)
- [Serving Models](https://docs.redhat.com/en/documentation/red_hat_openshift_ai_cloud_service/1/html-single/serving_models/index)

### Nouveaut√©s et releases
- [Nouvelles fonctionnalit√©s 2.22](https://docs.redhat.com/en/documentation/red_hat_openshift_ai_cloud_service/1/html/release_notes/new-features-and-enhancements_relnotes)
- [Issues r√©solues](https://docs.redhat.com/en/documentation/red_hat_openshift_ai_cloud_service/1/html/release_notes/resolved-issues_relnotes)

## üîß Installation et configuration

### Pr√©requis
1. **OpenShift Container Platform 4.19+**
2. **Privil√®ges cluster administrator**
3. **Stockage par d√©faut** configur√© et provisionnement dynamique
4. **Pour KServe** : Installation des op√©rateurs Serverless et Service Mesh

### √âtapes d'installation
1. **Installer l'op√©rateur** depuis OperatorHub
2. **Cr√©er DataScienceCluster** avec composants souhait√©s
3. **Configurer le stockage** S3-compatible
4. **Activer GPU** si n√©cessaire
5. **Configurer l'authentification** selon les besoins

---

**Bas√© sur** : Documentation officielle Red Hat OpenShift AI 2.22  
**Compatible** : OpenShift Container Platform 4.19+
